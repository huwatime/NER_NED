Prepare Clueweb Ground Truth
============================

0. Prepare clueweb docsfile and wordsfile.

   Files can be found under
   /nfs/datasets/clueweb_freebase_qlever/clueweb-freebase.withstop.docsfile
   /nfs/datasets/clueweb_freebase_qlever/clueweb-freebase.withstop.wordsfile

   The format is described on
   https://github.com/ad-freiburg/QLever/blob/master/docs/sparql_plus_text.md


1. Run gen_clueweb_freebase_iob_main to generate the IOB-format ground truth.

   Output file is one sentence per line in the format of
   LINE_NO <TAB> WORD1\TAG1\[IOB] <SPACE> WORD2\TAG2\[IOB] <SPACE> ...

   In the case of B, replace B by freebase ID.
   If no tagging information, replace TAG by "?".

   * It takes about 7 hours to process 500 million lines.


2. Run gen_clueweb_wikidata_iob_main to replace freebase IDs with wikidata IDs
   in the ground truth.

   Require an ID mapping file, which can be found under
   /nfs/students/yi-chun-lin/database/wikidata-freebase-id-mapping.csv

   It is generated by qLever at
   http://qlever.informatik.uni-freiburg.de/Wikidata_Full

   * It takes about 1 hour to process 500 million lines.


Prepare CoNLL Ground Truth
==========================

3. Run gen_conll_wikidata_iob_main to generate the IOB-format file

   Output file is one sentence per line in the format of
   LINE_NO <TAB> WORD1\TAG1\[IOB] <SPACE> WORD2\TAG2\[IOB] <SPACE> ...

   In the case of B, replace B by Wikidata QID.
   If no tagging information, replace TAG by "?".

   See the usage of gen_conll_wikidata_iob_main for more details.


Generate Algorithm Results
==========================

4. Given the ground truth file, run batch_run_ner_ned.py to generate algorithm results.

   Output file is one sentence per line in the format of
   LINE_NO <TAB> TRUTH_LINE <TAB> ALG_LINE

   where TRUTH_LINE and ALG_LINE are both in the format of
   WORD1\TAG1\[IOB] <SPACE> WORD2\TAG2\[IOB] <SPACE> ...


Evaluation
==========

5. Run evaluate_main to evaluate the algorithm results.

   It generates a folder with one state file and two detail files.
   The state file contains statistics like the number of tp, fp, fn etc.
   The detail files contain the byte-offset information for sampling a random sentence of certain type from the algorithm outputs.
   These files are used in web interface for a better understanding.
